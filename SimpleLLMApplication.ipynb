{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07407c52-40cd-415f-ae8e-575d3b71b013",
   "metadata": {},
   "source": [
    "# Building simple LLM application with Jupyter Notebook configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74472a2d-4da2-4daa-978d-fd7dcf48174f",
   "metadata": {},
   "source": [
    "Reference: <a href=\"https://python.langchain.com/docs/tutorials/llm_chain/\">Build a simple LLM application with chat models and prompt templates </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df250ba2-47e7-47dc-9f42-7ad1676ec1ec",
   "metadata": {},
   "source": [
    "## Ensure your python is using OpenSSL instead of LibreSSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "693f6952-c06e-4a74-8403-d3dc771648b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSSL 3.4.0 22 Oct 2024\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "print(ssl.OPENSSL_VERSION)\n",
    "## For Mac users Your openSSL_VERSION should be OpenSSL, if not reinstall python using brew "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03137db7-c72f-44ba-8ad8-1af3944a43c9",
   "metadata": {},
   "source": [
    "## Setting up Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e996de-e718-4037-8590-ae4eebd44f9b",
   "metadata": {},
   "source": [
    "The steps to configure Jupyter Notebook for your virtual environment are:\n",
    "<ol>\n",
    "    <li>Install Jupyter Notebook</li>\n",
    "    <li>Create virtual environment in your project directory</li>  \n",
    "    <b>python -m venv langchain-env</b>\n",
    "    <li>Enter virtual environment</li>\n",
    "    <b>source langchain-env/bin/activate</b>\n",
    "    <li>Install ipykernel</li>\n",
    "    <b>pip install jupyter ipykernel</b>\n",
    "    <li>Run Jupyter Notebook from virtual environment</li>\n",
    "    <b>python -m ipykernel install --user --name=langchain-env --display-name \"Python (langchain-env)\"</b>\n",
    "    <li>Navigate kernel in your notebook. Kernel > Change Kernel > Your Python virtual environment </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d0cd4-0f36-4905-afed-718fea7bc944",
   "metadata": {},
   "source": [
    "This command should point you to the directory of your virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1859b1-3338-45f3-9d0c-0602bf383c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a80eff-a848-44c5-9c7d-fa81941b12d9",
   "metadata": {},
   "source": [
    "## (For Windows Users) Set up .env configuration file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629e519f-5a7c-4f11-bab9-ad8d1d181aa7",
   "metadata": {},
   "source": [
    "This is how your .env file should look like:\n",
    "```bash\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_API_KEY=your_api_key_here\n",
    "OPENAI_API_KEY=your_openai_api_key_here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec66e5b-378e-4a3b-ad46-e9c361edc189",
   "metadata": {},
   "source": [
    "You will have to install dotenv to load your environment variables.\n",
    "Run this block of code to load your environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ee9e1-cc0f-454d-bc97-4b754b80d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61a5d72-8bbb-4e63-8d20-3c5274ab6d08",
   "metadata": {},
   "source": [
    "## (For Mac Users) Set up .zshrc configuration file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0def60-adf8-4a3f-a2a2-7bcdccc87b5c",
   "metadata": {},
   "source": [
    "This is how your configuration file should look like:\n",
    "\n",
    ".zshrc config\n",
    "```bash\n",
    "export LANGCHAIN_TRACING_V2=\"true\"\n",
    "export LANGCHAIN_API_KEY=\"YOUR_LANGCHAIN_KEY\"\n",
    "export OPENAI_API_KEY=\"YOUR_OPENAPI_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c72a8-f4ce-4e70-8ac0-331a2ae8379b",
   "metadata": {},
   "source": [
    "## Configure Langchain Smith to view usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88816cb6-8146-4436-9c67-0415664449ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this before running all your codes\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a65dcb-02d4-4177-a641-842b7a5c8d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c319054-3053-4285-abad-cf43dec8c161",
   "metadata": {},
   "source": [
    "## Install Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa1704-8b31-4800-87a9-4f8c203503c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce943880-1aaa-488b-9174-5205dd863739",
   "metadata": {},
   "source": [
    "## Start building your simple LLM application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c8f95d8-35bf-41f9-bf45-31016a4e81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8897633-d7f6-43ad-bc1b-64eb1899dcd0",
   "metadata": {},
   "source": [
    "<b>If you're getting a rate-limiting error, you have to set up billing/payment in your openAI settings</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdb1352b-a271-40f3-9fb2-ebe92d320ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 20, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'stop', 'logprobs': None}, id='run-cbe87e0a-be1f-4c8d-8e30-38aa1eba834f-0', usage_metadata={'input_tokens': 20, 'output_tokens': 4, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2330500-e5f8-48b8-b436-a6f53d0297a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|C|iao|!||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d39c05e-cc7a-43ae-bd3a-5c09969f3253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n",
    "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fea1627-5b1a-4160-9ffb-f76b4de210a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d8e458c-35f5-4177-9009-6425d6ded110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (simplellmvenv)",
   "language": "python",
   "name": "simplellvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
